{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import geopandas\n",
    "from shapely.geometry import Polygon\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = sqlite3.connect('../us_wildfire_dataset/FPA_FOD_20170508.sqlite')\n",
    "df = pd.read_sql_query(\"SELECT DISCOVERY_DATE, CONT_DATE, LATITUDE, LONGITUDE, STATE, FIRE_NAME, FIRE_SIZE_CLASS, FIRE_SIZE,STAT_CAUSE_DESCR FROM fires\", cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def filter_raw_data(df, state='CA', min_class=None):\n",
    "\n",
    "    # drop states\n",
    "    df_filt = df[df.STATE == 'CA']\n",
    "    df_filt = df_filt.drop(['STATE'], axis=1)\n",
    "\n",
    "    # drop fire classes\n",
    "    if min_class is not None:\n",
    "        df_filt.FIRE_SIZE_CLASS = df_filt.FIRE_SIZE_CLASS.apply(ord)\n",
    "        df_filt = df_filt[df_filt.FIRE_SIZE_CLASS >= ord(min_class)]\n",
    "\n",
    "    # reformat dates\n",
    "    df_filt.DISCOVERY_DATE = pd.to_datetime(df['DISCOVERY_DATE'], unit='D', origin='julian')\n",
    "    df_filt.CONT_DATE = pd.to_datetime(df['CONT_DATE'], unit='D', origin='julian')\n",
    "\n",
    "    # convert coordinates\n",
    "    df_filt = geopandas.GeoDataFrame(df_filt, geometry=geopandas.points_from_xy(\n",
    "        df_filt.LONGITUDE, df_filt.LATITUDE))\n",
    "    df_filt = df_filt.drop(['LONGITUDE'], axis=1)\n",
    "    df_filt = df_filt.drop(['LATITUDE'], axis=1)\n",
    "    df_filt.insert(2, 'COORD', df_filt.pop('geometry'))\n",
    "\n",
    "    # remove missing values\n",
    "    df_filt = df_filt.dropna()\n",
    "\n",
    "    # reformat head\n",
    "    df_filt.columns = [\n",
    "        'start_date', 'end_date', 'geometry',\n",
    "        'name', 'size_class', 'size', 'cause'\n",
    "    ]\n",
    "\n",
    "    # sort by start dates\n",
    "    df_filt = df_filt.sort_values(by='start_date')\n",
    "    df_filt = df_filt.reset_index()\n",
    "\n",
    "    return df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def extract_geo_fires(df, area):\n",
    "\n",
    "    # return fires within polygon\n",
    "    res = df[df.within(area)]\n",
    "    return res\n",
    "\n",
    "\n",
    "def build_geo_grid(df, grid_area, square_size, verbose=False):\n",
    "    bounds = grid_area.bounds\n",
    "\n",
    "    # calculate number of grids in lat/long directions\n",
    "    long_steps = int((bounds[2] - bounds[0]) / square_size)\n",
    "    lat_steps = int((bounds[3] - bounds[1]) / square_size)\n",
    "\n",
    "    grid_df = []\n",
    "    prog, total = 0, long_steps * lat_steps\n",
    "    for i in range(long_steps):\n",
    "        for j in range(lat_steps):\n",
    "\n",
    "            # update progress\n",
    "            prog += 1\n",
    "            if verbose and prog % 10 == 0:\n",
    "                print('Progress: {}/{}'.format(prog, total), flush=True)\n",
    "            \n",
    "            # get south-east grid square corner\n",
    "            c_lon = bounds[0] + i * square_size\n",
    "            c_lat = bounds[1] + j * square_size\n",
    "\n",
    "            # create grid square\n",
    "            grid = Polygon([\n",
    "                (c_lon, c_lat), \n",
    "                (c_lon + square_size, c_lat), \n",
    "                (c_lon, c_lat + square_size), \n",
    "                (c_lon + square_size, c_lat + square_size)\n",
    "            ])\n",
    "\n",
    "            fires = extract_geo_fires(df, grid)\n",
    "            grid_df.append([uuid.uuid4(), grid, fires.index])\n",
    "\n",
    "    # build grid df\n",
    "    grid_df = geopandas.GeoDataFrame(grid_df)\n",
    "    grid_df.columns = ['grid_id', 'grid_square', 'fire_indices']\n",
    "    return grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Progress: 10/400\nProgress: 20/400\nProgress: 30/400\nProgress: 40/400\nProgress: 50/400\nProgress: 60/400\nProgress: 70/400\nProgress: 80/400\nProgress: 90/400\nProgress: 100/400\nProgress: 110/400\nProgress: 120/400\nProgress: 130/400\nProgress: 140/400\nProgress: 150/400\nProgress: 160/400\nProgress: 170/400\nProgress: 180/400\nProgress: 190/400\nProgress: 200/400\nProgress: 210/400\nProgress: 220/400\nProgress: 230/400\nProgress: 240/400\nProgress: 250/400\nProgress: 260/400\nProgress: 270/400\nProgress: 280/400\nProgress: 290/400\nProgress: 300/400\nProgress: 310/400\nProgress: 320/400\nProgress: 330/400\nProgress: 340/400\nProgress: 350/400\nProgress: 360/400\nProgress: 370/400\nProgress: 380/400\nProgress: 390/400\nProgress: 400/400\n"
    }
   ],
   "source": [
    "# coordinate-square north of San Bernardino/Riverside \n",
    "p = Polygon([(-118, 34), (-118, 36), (-116, 34), (-116, 36)])\n",
    "\n",
    "# filter raw data from dataset and build sexy format\n",
    "df_filt = filter_raw_data(df)\n",
    "\n",
    "# df_filt is ordered by start_date with the following columns:\n",
    "#   'start_date', 'end_date', 'geometry', 'name', 'size_class', 'size', 'cause'\n",
    "\n",
    "# build df with each grid square area (from grid area `p` with grid square size 0.1) and corresponding fires indices (which indexes complete list of fires in df_filt)\n",
    "grid_df = build_geo_grid(df_filt, p, 0.1, verbose=True)\n",
    "\n",
    "# grid_df has the following columns:\n",
    "#    'grid_id', 'grid_square', 'fire_indices'\n",
    "#    grid_id: a random uuid to identify the grid square for later\n",
    "#    grid_square: polygon object of the grid square\n",
    "#    fire_indices: list of indices of the fires from df_filt within the grid_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def label_grid_square(df, grid_df, start_date='1992-01', end_date='2015-12', verbose=False):\n",
    "    \n",
    "    # build date range (in months)\n",
    "    date_range = [str(d) for d in np.arange(\n",
    "        start_date, \n",
    "        end_date, \n",
    "        dtype='datetime64[M]'\n",
    "    )]    \n",
    "\n",
    "    # iterate over all grid squares \n",
    "    label_df = []\n",
    "    prog, total = 0, grid_df.shape[0]\n",
    "    for i in range(grid_df.shape[0]):\n",
    "        \n",
    "        # update progress\n",
    "        prog += 1\n",
    "        if verbose and prog % 10 == 0:\n",
    "            print('Progress: {}/{}'.format(prog, total), flush=True)\n",
    "                \n",
    "        # get grid square fires\n",
    "        id = grid_df.loc[i, 'grid_id']\n",
    "        grid_square = grid_df.loc[i, 'grid_square']\n",
    "        fire_indices = list(grid_df.loc[i, 'fire_indices'])\n",
    "        fires = df.loc[fire_indices, :]\n",
    "        \n",
    "        # collect all months in fire date range\n",
    "        months = []\n",
    "        for _, row in fires.iterrows(): \n",
    "            start = row.start_date.date()\n",
    "            end = (row.end_date + pd.DateOffset(months=1)).date()\n",
    "            months.extend([str(d) for d in np.arange(start, end, dtype='datetime64[M]')])\n",
    "        fire_months = list(set(months))\n",
    "        \n",
    "        # label fire months\n",
    "        month_labels = []\n",
    "        for month in date_range:\n",
    "            if month in fire_months: month_labels.append(1)\n",
    "            else: month_labels.append(0)\n",
    "        \n",
    "        # add labels\n",
    "        labels = [id, grid_square] + month_labels\n",
    "        label_df.append(labels)\n",
    "        \n",
    "    # build label df\n",
    "    label_df = pd.DataFrame(label_df)\n",
    "    label_df.columns = ['grid_id', 'grid_square'] + date_range\n",
    "    return label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Progress: 10/400\nProgress: 20/400\nProgress: 30/400\nProgress: 40/400\nProgress: 50/400\nProgress: 60/400\nProgress: 70/400\nProgress: 80/400\nProgress: 90/400\nProgress: 100/400\nProgress: 110/400\nProgress: 120/400\nProgress: 130/400\nProgress: 140/400\nProgress: 150/400\nProgress: 160/400\nProgress: 170/400\nProgress: 180/400\nProgress: 190/400\nProgress: 200/400\nProgress: 210/400\nProgress: 220/400\nProgress: 230/400\nProgress: 240/400\nProgress: 250/400\nProgress: 260/400\nProgress: 270/400\nProgress: 280/400\nProgress: 290/400\nProgress: 300/400\nProgress: 310/400\nProgress: 320/400\nProgress: 330/400\nProgress: 340/400\nProgress: 350/400\nProgress: 360/400\nProgress: 370/400\nProgress: 380/400\nProgress: 390/400\nProgress: 400/400\n"
    }
   ],
   "source": [
    "    \n",
    "# labels whether there was a fire in each grid square \n",
    "label_df = label_grid_square(df_filt, grid_df, verbose=True)\n",
    "\n",
    "# label_df has the following columns:\n",
    "#    'grid_id', 'grid_square', 'months ...'\n",
    "#    grid_id: a random uuid to identify the grid square for later\n",
    "#    grid_square: polygon object of the grid square\n",
    "#    indices: the rest of the columns are a label for each month (0 if there was no fire in the grid square during them onth and 1 otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "grid_id  \\\n0    5bb1229d-69c6-4eec-acb9-09e20c15bdd3   \n1    b34b04ff-8d36-4550-9c28-74a58a267826   \n2    5f55f152-a875-4ede-aac0-e0ff8528f5e5   \n3    66a34d7e-95cb-4803-8be1-0927f9e905db   \n4    96d4679b-1297-482c-bc07-a20d641eb1b9   \n..                                    ...   \n395  7d11cfb8-2c8b-4d46-813b-0ec92f08b8e3   \n396  23db8c5e-8e5c-4e5a-9a99-9f5db9e34835   \n397  4e69582d-7d1a-46b9-a9d9-5dbbc4bca259   \n398  729f8d33-c7b0-4690-879a-46a4a68a69c2   \n399  0fdd78f5-797a-47fa-970f-6affef59113b   \n\n                                           grid_square  1992-01  1992-02  \\\n0    POLYGON ((-118 34, -117.9 34, -118 34.1, -117....        0        0   \n1    POLYGON ((-118 34.1, -117.9 34.1, -118 34.2, -...        0        0   \n2    POLYGON ((-118 34.2, -117.9 34.2, -118 34.3, -...        0        0   \n3    POLYGON ((-118 34.3, -117.9 34.3, -118 34.4, -...        0        0   \n4    POLYGON ((-118 34.4, -117.9 34.4, -118 34.5, -...        0        0   \n..                                                 ...      ...      ...   \n395  POLYGON ((-116.1 35.5, -116 35.5, -116.1 35.6,...        0        0   \n396  POLYGON ((-116.1 35.6, -116 35.6, -116.1 35.7,...        0        0   \n397  POLYGON ((-116.1 35.7, -116 35.7, -116.1 35.8,...        0        0   \n398  POLYGON ((-116.1 35.8, -116 35.8, -116.1 35.9,...        0        0   \n399  POLYGON ((-116.1 35.9, -116 35.9, -116.1 36, -...        0        0   \n\n     1992-03  1992-04  1992-05  1992-06  1992-07  1992-08  ...  2015-02  \\\n0          0        0        0        0        0        0  ...        0   \n1          0        0        0        0        0        0  ...        0   \n2          0        0        0        0        0        0  ...        0   \n3          0        0        0        0        0        0  ...        0   \n4          0        0        0        0        0        0  ...        0   \n..       ...      ...      ...      ...      ...      ...  ...      ...   \n395        0        0        0        0        0        0  ...        0   \n396        0        0        0        0        0        0  ...        0   \n397        0        0        0        0        0        0  ...        0   \n398        0        0        0        0        0        0  ...        0   \n399        0        0        0        0        0        0  ...        0   \n\n     2015-03  2015-04  2015-05  2015-06  2015-07  2015-08  2015-09  2015-10  \\\n0          0        0        0        0        0        0        0        0   \n1          0        0        0        0        0        0        0        0   \n2          0        0        0        0        0        0        0        0   \n3          0        0        0        0        0        0        0        0   \n4          0        0        0        0        0        0        0        0   \n..       ...      ...      ...      ...      ...      ...      ...      ...   \n395        0        0        0        0        0        0        0        0   \n396        0        0        0        0        0        0        0        0   \n397        0        0        0        0        0        0        0        0   \n398        0        0        0        0        0        0        0        0   \n399        0        0        0        0        0        0        0        0   \n\n     2015-11  \n0          0  \n1          0  \n2          0  \n3          0  \n4          0  \n..       ...  \n395        0  \n396        0  \n397        0  \n398        0  \n399        0  \n\n[400 rows x 289 columns]\n"
    }
   ],
   "source": [
    "print(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "num_zeros = 0\n",
    "num_subsequent_1s = 0\n",
    "total_iters = 0\n",
    "for index, row in label_df.iterrows():\n",
    "    for rowIndex, col in enumerate(row[2:-1]):\n",
    "        # if not on fire\n",
    "        total_iters += 1\n",
    "        if col == 0:\n",
    "            num_zeros += 1\n",
    "            # include implicit conversion to tuple of bounds instead of polygon shape; will make working with earth engine easier\n",
    "            output.append((row[0], row[1].bounds, label_df.columns[rowIndex + 2], row[rowIndex + 1 + 2]))\n",
    "            if row[rowIndex + 1 + 2] == 1:\n",
    "                num_subsequent_1s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "112366\n1563\n114400\n"
    }
   ],
   "source": [
    "print(num_zeros)\n",
    "print(num_subsequent_1s)\n",
    "print(total_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# save the corresponding data structure to disk\n",
    "import pickle\n",
    "with open(\"../us_wildfire_dataset/labelled_temporal_polygons.pkl\", \"wb\") as f:\n",
    "    pickle.dump(output, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p>To authorize access needed by Earth Engine, open the following\n        URL in a web browser and follow the instructions:</p>\n        <p><a href=https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=idslZvDK6bvedfNL0RQ0EV7jPya52wSh-A-AWQQarIc&code_challenge_method=S256>https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=idslZvDK6bvedfNL0RQ0EV7jPya52wSh-A-AWQQarIc&code_challenge_method=S256</a></p>\n        <p>The authorization workflow will generate a code, which you\n        should paste in the box below</p>\n        "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nSuccessfully saved authorization token.\n"
    }
   ],
   "source": [
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ee.Geometry({\n  \"type\": \"Polygon\",\n  \"coordinates\": [\n    [\n      [\n        -118.0,\n        34.1\n      ],\n      [\n        -118.0,\n        34.0\n      ],\n      [\n        -117.9,\n        34.0\n      ],\n      [\n        -117.9,\n        34.1\n      ]\n    ]\n  ],\n  \"evenOdd\": true\n})\n"
    }
   ],
   "source": [
    "for item in output[:1]:\n",
    "    uuid, coords, date, label = item\n",
    "    # we want to grab the polygon, and download the associated image files\n",
    "    landsat = ee.Image('LANDSAT/LC08/C01/T1_TOA/LC08_123032_20140515').select(['B1', 'B2', 'B3'])\n",
    "    geometry = ee.Geometry.Rectangle(list(coords))\n",
    "    print(geometry)\n",
    "    task = ee.batch.Export.image.toDrive(image=landsat, folder=\"world_images\", region=geometry, scale=30, description=\"Hello world, I am a photo of you\", fileFormat=\"TFRecord\")\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'state': 'FAILED',\n 'description': 'Hello world, I am a photo of you',\n 'creation_timestamp_ms': 1589934931057,\n 'update_timestamp_ms': 1589934942015,\n 'start_timestamp_ms': 1589934939556,\n 'task_type': 'EXPORT_IMAGE',\n 'error_message': 'Patch dimensions must be fully specified.',\n 'id': 'MJ53ZGTQHMGGD4W2AK2HLQN4',\n 'name': 'projects/earthengine-legacy/operations/MJ53ZGTQHMGGD4W2AK2HLQN4'}"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "task.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}