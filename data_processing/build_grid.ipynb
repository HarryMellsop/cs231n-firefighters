{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import geopandas\n",
    "from shapely.geometry import Polygon\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = sqlite3.connect('../us_wildfire_dataset/FPA_FOD_20170508.sqlite')\n",
    "df = pd.read_sql_query(\"SELECT DISCOVERY_DATE, CONT_DATE, LATITUDE, LONGITUDE, STATE, FIRE_NAME, FIRE_SIZE_CLASS, FIRE_SIZE, STAT_CAUSE_DESCR FROM fires;\", cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def filter_raw_data(df, state='CA', min_class=None):\n",
    "\n",
    "    # drop states\n",
    "    df_filt = df[df.STATE == 'CA']\n",
    "    df_filt = df_filt.drop(['STATE'], axis=1)\n",
    "\n",
    "    # drop fire classes\n",
    "    if min_class is not None:\n",
    "        df_filt.FIRE_SIZE_CLASS = df_filt.FIRE_SIZE_CLASS.apply(ord)\n",
    "        df_filt = df_filt[df_filt.FIRE_SIZE_CLASS >= ord(min_class)]\n",
    "\n",
    "    # reformat dates\n",
    "    df_filt.DISCOVERY_DATE = pd.to_datetime(df['DISCOVERY_DATE'], unit='D', origin='julian')\n",
    "    df_filt.CONT_DATE = pd.to_datetime(df['CONT_DATE'], unit='D', origin='julian')\n",
    "\n",
    "    # convert coordinates\n",
    "    df_filt = geopandas.GeoDataFrame(df_filt, geometry=geopandas.points_from_xy(\n",
    "        df_filt.LONGITUDE, df_filt.LATITUDE))\n",
    "    df_filt = df_filt.drop(['LONGITUDE'], axis=1)\n",
    "    df_filt = df_filt.drop(['LATITUDE'], axis=1)\n",
    "    df_filt.insert(2, 'COORD', df_filt.pop('geometry'))\n",
    "\n",
    "    # remove missing values\n",
    "    df_filt = df_filt.dropna()\n",
    "\n",
    "    # reformat head\n",
    "    df_filt.columns = [\n",
    "        'start_date', 'end_date', 'geometry',\n",
    "        'name', 'size_class', 'size', 'cause'\n",
    "    ]\n",
    "\n",
    "    # sort by start dates\n",
    "    df_filt = df_filt.sort_values(by='start_date')\n",
    "    df_filt = df_filt.reset_index()\n",
    "\n",
    "    return df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def extract_geo_fires(df, area):\n",
    "\n",
    "    # return fires within polygon\n",
    "    res = df[df.within(area)]\n",
    "    return res\n",
    "\n",
    "\n",
    "def build_geo_grid(df, grid_area, square_size, verbose=False):\n",
    "    bounds = grid_area.bounds\n",
    "\n",
    "    # calculate number of grids in lat/long directions\n",
    "    long_steps = int((bounds[2] - bounds[0]) / square_size)\n",
    "    lat_steps = int((bounds[3] - bounds[1]) / square_size)\n",
    "\n",
    "    grid_df = []\n",
    "    prog, total = 0, long_steps * lat_steps\n",
    "    for i in range(long_steps):\n",
    "        for j in range(lat_steps):\n",
    "\n",
    "            # update progress\n",
    "            prog += 1\n",
    "            if verbose and prog % 10 == 0:\n",
    "                print('Progress: {}/{}'.format(prog, total), flush=True)\n",
    "            \n",
    "            # get south-east grid square corner\n",
    "            c_lon = bounds[0] + i * square_size\n",
    "            c_lat = bounds[1] + j * square_size\n",
    "\n",
    "            # create grid square\n",
    "            grid = Polygon([\n",
    "                (c_lon, c_lat), \n",
    "                (c_lon + square_size, c_lat), \n",
    "                (c_lon, c_lat + square_size), \n",
    "                (c_lon + square_size, c_lat + square_size)\n",
    "            ])\n",
    "            \n",
    "            fires = extract_geo_fires(df, grid)\n",
    "            grid_df.append([uuid.uuid4(), grid, fires.index])\n",
    "\n",
    "    # build grid df\n",
    "    grid_df = geopandas.GeoDataFrame(grid_df)\n",
    "    grid_df.columns = ['grid_id', 'grid_square', 'fire_indices']\n",
    "    return grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        index start_date   end_date                     geometry  \\\n0      358860 1992-01-12 1992-01-14  POINT (-114.50000 33.00000)   \n1      191963 1992-01-27 1992-01-28  POINT (-116.63420 33.16670)   \n2       49037 1992-02-04 1992-02-05  POINT (-119.85167 37.58833)   \n3       46918 1992-02-04 1992-02-04  POINT (-120.35833 38.48000)   \n4      213370 1992-03-18 1992-03-21  POINT (-114.70080 33.23340)   \n...       ...        ...        ...                          ...   \n6460  1790615 2015-10-29 2015-11-04  POINT (-119.63861 34.48028)   \n6461  1797742 2015-11-07 2015-11-08  POINT (-118.87245 34.16236)   \n6462  1872260 2015-11-14 2015-11-14  POINT (-120.31460 36.73433)   \n6463  1871634 2015-11-17 2015-11-17  POINT (-117.29967 33.83589)   \n6464  1792882 2015-12-07 2015-12-07  POINT (-118.33667 34.27917)   \n\n                 name  size_class    size              cause  \n0            FERGUSON          67    60.0      Miscellaneous  \n1          SCHOLHOUSE          67    47.0     Debris Burning  \n2              SNYDER          67    30.0     Debris Burning  \n3                SALT          67    58.0      Miscellaneous  \n4             WALTERS          70  1800.0     Debris Burning  \n...               ...         ...     ...                ...  \n6460        GIBRALTER          67    21.0      Miscellaneous  \n6461          POTRERO          67    29.6  Missing/Undefined  \n6462            RIVER          67    20.0  Missing/Undefined  \n6463  SOUDER ST  MEAD          68   100.0      Miscellaneous  \n6464        WHEATLAND          67    11.0      Equipment Use  \n\n[6465 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>geometry</th>\n      <th>name</th>\n      <th>size_class</th>\n      <th>size</th>\n      <th>cause</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>358860</td>\n      <td>1992-01-12</td>\n      <td>1992-01-14</td>\n      <td>POINT (-114.50000 33.00000)</td>\n      <td>FERGUSON</td>\n      <td>67</td>\n      <td>60.0</td>\n      <td>Miscellaneous</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>191963</td>\n      <td>1992-01-27</td>\n      <td>1992-01-28</td>\n      <td>POINT (-116.63420 33.16670)</td>\n      <td>SCHOLHOUSE</td>\n      <td>67</td>\n      <td>47.0</td>\n      <td>Debris Burning</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49037</td>\n      <td>1992-02-04</td>\n      <td>1992-02-05</td>\n      <td>POINT (-119.85167 37.58833)</td>\n      <td>SNYDER</td>\n      <td>67</td>\n      <td>30.0</td>\n      <td>Debris Burning</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>46918</td>\n      <td>1992-02-04</td>\n      <td>1992-02-04</td>\n      <td>POINT (-120.35833 38.48000)</td>\n      <td>SALT</td>\n      <td>67</td>\n      <td>58.0</td>\n      <td>Miscellaneous</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>213370</td>\n      <td>1992-03-18</td>\n      <td>1992-03-21</td>\n      <td>POINT (-114.70080 33.23340)</td>\n      <td>WALTERS</td>\n      <td>70</td>\n      <td>1800.0</td>\n      <td>Debris Burning</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6460</th>\n      <td>1790615</td>\n      <td>2015-10-29</td>\n      <td>2015-11-04</td>\n      <td>POINT (-119.63861 34.48028)</td>\n      <td>GIBRALTER</td>\n      <td>67</td>\n      <td>21.0</td>\n      <td>Miscellaneous</td>\n    </tr>\n    <tr>\n      <th>6461</th>\n      <td>1797742</td>\n      <td>2015-11-07</td>\n      <td>2015-11-08</td>\n      <td>POINT (-118.87245 34.16236)</td>\n      <td>POTRERO</td>\n      <td>67</td>\n      <td>29.6</td>\n      <td>Missing/Undefined</td>\n    </tr>\n    <tr>\n      <th>6462</th>\n      <td>1872260</td>\n      <td>2015-11-14</td>\n      <td>2015-11-14</td>\n      <td>POINT (-120.31460 36.73433)</td>\n      <td>RIVER</td>\n      <td>67</td>\n      <td>20.0</td>\n      <td>Missing/Undefined</td>\n    </tr>\n    <tr>\n      <th>6463</th>\n      <td>1871634</td>\n      <td>2015-11-17</td>\n      <td>2015-11-17</td>\n      <td>POINT (-117.29967 33.83589)</td>\n      <td>SOUDER ST  MEAD</td>\n      <td>68</td>\n      <td>100.0</td>\n      <td>Miscellaneous</td>\n    </tr>\n    <tr>\n      <th>6464</th>\n      <td>1792882</td>\n      <td>2015-12-07</td>\n      <td>2015-12-07</td>\n      <td>POINT (-118.33667 34.27917)</td>\n      <td>WHEATLAND</td>\n      <td>67</td>\n      <td>11.0</td>\n      <td>Equipment Use</td>\n    </tr>\n  </tbody>\n</table>\n<p>6465 rows Ã— 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Progress: 10/256\nProgress: 20/256\nProgress: 30/256\nProgress: 40/256\nProgress: 50/256\nProgress: 60/256\nProgress: 70/256\nProgress: 80/256\nProgress: 90/256\nProgress: 100/256\nProgress: 110/256\nProgress: 120/256\nProgress: 130/256\nProgress: 140/256\nProgress: 150/256\nProgress: 160/256\nProgress: 170/256\nProgress: 180/256\nProgress: 190/256\nProgress: 200/256\nProgress: 210/256\nProgress: 220/256\nProgress: 230/256\nProgress: 240/256\nProgress: 250/256\n"
    }
   ],
   "source": [
    "# coordinate-square north of San Bernardino/Riverside \n",
    "p = Polygon([(-124, 38), (-124, 42), (-120, 38), (-120, 42)])\n",
    "\n",
    "# filter raw data from dataset and build sexy format\n",
    "df_filt = filter_raw_data(df, state='CA', min_class='C')\n",
    "\n",
    "# df_filt is ordered by start_date with the following columns:\n",
    "#   'start_date', 'end_date', 'geometry', 'name', 'size_class', 'size', 'cause'\n",
    "\n",
    "# build df with each grid square area (from grid area `p` with grid square size 0.1) and corresponding fires indices (which indexes complete list of fires in df_filt)\n",
    "grid_df = build_geo_grid(df_filt, p, 0.25, verbose=True)\n",
    "\n",
    "# grid_df has the following columns:\n",
    "#    'grid_id', 'grid_square', 'fire_indices'\n",
    "#    grid_id: a random uuid to identify the grid square for later\n",
    "#    grid_square: polygon object of the grid square\n",
    "#    fire_indices: list of indices of the fires from df_filt within the grid_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def label_grid_square(df, grid_df, start_date='1992-01', end_date='2015-12', verbose=False):\n",
    "    \n",
    "    # build date range (in months)\n",
    "    date_range = [str(d) for d in np.arange(\n",
    "        start_date, \n",
    "        end_date, \n",
    "        dtype='datetime64[M]'\n",
    "    )]    \n",
    "\n",
    "    # iterate over all grid squares \n",
    "    label_df = []\n",
    "    prog, total = 0, grid_df.shape[0]\n",
    "    for i in range(grid_df.shape[0]):\n",
    "        \n",
    "        # update progress\n",
    "        prog += 1\n",
    "        if verbose and prog % 10 == 0:\n",
    "            print('Progress: {}/{}'.format(prog, total), flush=True)\n",
    "                \n",
    "        # get grid square fires\n",
    "        id = grid_df.loc[i, 'grid_id']\n",
    "        grid_square = grid_df.loc[i, 'grid_square']\n",
    "        fire_indices = list(grid_df.loc[i, 'fire_indices'])\n",
    "        fires = df.loc[fire_indices, :]\n",
    "        \n",
    "        # collect all months in fire date range\n",
    "        months = []\n",
    "        for _, row in fires.iterrows(): \n",
    "            start = row.start_date.date()\n",
    "            end = (row.end_date + pd.DateOffset(months=1)).date()\n",
    "            months.extend([str(d) for d in np.arange(start, end, dtype='datetime64[M]')])\n",
    "        fire_months = list(set(months))\n",
    "        \n",
    "        # label fire months\n",
    "        month_labels = []\n",
    "        for month in date_range:\n",
    "            if month in fire_months: month_labels.append(1)\n",
    "            else: month_labels.append(0)\n",
    "        \n",
    "        # add labels\n",
    "        labels = [id, grid_square] + month_labels\n",
    "        label_df.append(labels)\n",
    "        \n",
    "    # build label df\n",
    "    label_df = pd.DataFrame(label_df)\n",
    "    label_df.columns = ['grid_id', 'grid_square'] + date_range\n",
    "    return label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(label_data, max_batch_size = 50):\n",
    "\n",
    "  num_datapoints = label_data.size().getInfo()\n",
    "  indices = np.arange(num_datapoints)\n",
    "\n",
    "  num_batches = num_datapoints // MAX_BATCH_SIZE + 1\n",
    "\n",
    "  return np.array_split(np.arange(label_data.size().getInfo()), num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# labels whether there was a fire in each grid square \n",
    "label_df = label_grid_square(df_filt, grid_df, start_date='2000-01', end_date='2015-12', verbose=False)\n",
    "\n",
    "# label_df has the following columns:\n",
    "#    'grid_id', 'grid_square', 'months ...'\n",
    "#    grid_id: a random uuid to identify the grid square for later\n",
    "#    grid_square: polygon object of the grid square\n",
    "#    indices: the rest of the columns are a label for each month (0 if there was no fire in the grid square during them onth and 1 otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                grid_id  \\\n0  88eb7605-7262-430d-9d3c-a75494c72cd3   \n1  da2c8de8-fe14-4bd3-b7da-541aaeb508c4   \n2  754a037e-fba8-493b-82e1-9cd4f3a519b2   \n3  7e090195-c0cd-4a56-8cff-5944f4012bfd   \n4  417db21d-e246-4e6f-8ff2-9ab024121db5   \n\n                                         grid_square  2000-01  2000-02  \\\n0  POLYGON ((-124 38, -123.75 38, -124 38.25, -12...        0        0   \n1  POLYGON ((-124 38.25, -123.75 38.25, -124 38.5...        0        0   \n2  POLYGON ((-124 38.5, -123.75 38.5, -124 38.75,...        0        0   \n3  POLYGON ((-124 38.75, -123.75 38.75, -124 39, ...        0        0   \n4  POLYGON ((-124 39, -123.75 39, -124 39.25, -12...        0        0   \n\n   2000-03  2000-04  2000-05  2000-06  2000-07  2000-08  ...  2015-02  \\\n0        0        0        0        0        0        0  ...        0   \n1        0        0        0        0        0        0  ...        0   \n2        0        0        0        0        0        0  ...        0   \n3        0        0        0        0        0        0  ...        0   \n4        0        0        0        0        0        0  ...        0   \n\n   2015-03  2015-04  2015-05  2015-06  2015-07  2015-08  2015-09  2015-10  \\\n0        0        0        0        0        0        0        0        0   \n1        0        0        0        0        0        0        0        0   \n2        0        0        0        0        0        0        0        0   \n3        0        0        0        0        0        0        0        0   \n4        0        0        0        0        0        0        0        0   \n\n   2015-11  \n0        0  \n1        0  \n2        0  \n3        0  \n4        0  \n\n[5 rows x 193 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>grid_id</th>\n      <th>grid_square</th>\n      <th>2000-01</th>\n      <th>2000-02</th>\n      <th>2000-03</th>\n      <th>2000-04</th>\n      <th>2000-05</th>\n      <th>2000-06</th>\n      <th>2000-07</th>\n      <th>2000-08</th>\n      <th>...</th>\n      <th>2015-02</th>\n      <th>2015-03</th>\n      <th>2015-04</th>\n      <th>2015-05</th>\n      <th>2015-06</th>\n      <th>2015-07</th>\n      <th>2015-08</th>\n      <th>2015-09</th>\n      <th>2015-10</th>\n      <th>2015-11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>88eb7605-7262-430d-9d3c-a75494c72cd3</td>\n      <td>POLYGON ((-124 38, -123.75 38, -124 38.25, -12...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>da2c8de8-fe14-4bd3-b7da-541aaeb508c4</td>\n      <td>POLYGON ((-124 38.25, -123.75 38.25, -124 38.5...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>754a037e-fba8-493b-82e1-9cd4f3a519b2</td>\n      <td>POLYGON ((-124 38.5, -123.75 38.5, -124 38.75,...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7e090195-c0cd-4a56-8cff-5944f4012bfd</td>\n      <td>POLYGON ((-124 38.75, -123.75 38.75, -124 39, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>417db21d-e246-4e6f-8ff2-9ab024121db5</td>\n      <td>POLYGON ((-124 39, -123.75 39, -124 39.25, -12...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 193 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "num_zeros = 0\n",
    "num_subsequent_1s = 0\n",
    "total_iters = 0\n",
    "for index, row in label_df.iterrows():\n",
    "    # because we are using Landsat 7, let's make sure we constrain dates to be from 2000 onwards (hence the + 96)\n",
    "\n",
    "    if np.sum(row[2:]) <= 3: continue\n",
    "    for rowIndex, col in enumerate(row[2 + 96:-1]):\n",
    "        # if not on fire\n",
    "        total_iters += 1\n",
    "        if col == 0:\n",
    "            num_zeros += 1\n",
    "            # include implicit conversion to tuple of bounds instead of polygon shape; will make working with earth engine easier\n",
    "            output.append((row[0], row[1].bounds, label_df.columns[rowIndex + 2 + 96], row[rowIndex + 1 + 2 + 96]))\n",
    "            if row[rowIndex + 1 + 2 + 96] == 1:\n",
    "                num_subsequent_1s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total iterations: 10622\nTotal data points: 10172\nTotal data points with 1-label: 263\nTotal data points with 0-label: 9909\nPercentage of 1s: 2.586%\n"
    }
   ],
   "source": [
    "print('Total iterations: {}'.format(total_iters))\n",
    "print('Total data points: {}'.format(num_zeros))\n",
    "print('Total data points with 1-label: {}'.format(num_subsequent_1s))\n",
    "print('Total data points with 0-label: {}'.format(num_zeros - num_subsequent_1s))\n",
    "print('Percentage of 1s: {}%'.format(round(num_subsequent_1s / num_zeros * 100, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# save the corresponding data structure to disk\n",
    "import pickle\n",
    "with open(\"../us_wildfire_dataset/labelled_temporal_polygons.pkl\", \"wb\") as f:\n",
    "    pickle.dump(output, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10172\n"
    }
   ],
   "source": [
    "# load output back from the pickle\n",
    "with open(\"../us_wildfire_dataset/labelled_temporal_polygons.pkl\", \"rb\") as f:\n",
    "    unpickler = pickle.Unpickler(f)\n",
    "    output = unpickler.load()\n",
    "    print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(UUID('13a0f575-1dfa-4548-a1e2-c9316dabb02b'),\n (-124.0, 41.0, -123.75, 41.25),\n '2008-01',\n 0)"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0it [00:00, ?it/s]0.000000 complete\n2it [00:00,  2.29it/s]\n"
    }
   ],
   "source": [
    "from calendar import monthrange\n",
    "import tqdm\n",
    "\n",
    "totalIters = len(output)\n",
    "taskArray = []\n",
    "\n",
    "# change this number 10 to eventually download all of the required images.\n",
    "for index, item in tqdm.tqdm(enumerate(output)):\n",
    "    uuid, coords, date, label = item\n",
    "    year, month = date.split(\"-\")\n",
    "    year, month = int(year), int(month)\n",
    "\n",
    "    if index % 10 == 0: print(\"%f complete\" % (float(index) / float(totalIters)))\n",
    "\n",
    "    geometry = ee.Geometry.Rectangle(list(coords))\n",
    "\n",
    "    # because we are using LANDSAT7, we need to constrain our dates from 2000 onwards; so far, this has been done above (in cell 96)\n",
    "    collection = ee.ImageCollection(\"LANDSAT/LE07/C01/T1\").filterDate(ee.Date.fromYMD(year, month, 1), ee.Date.fromYMD(year, month, monthrange(year, month)[1])).filterBounds(geometry)\n",
    "    trueColor = collection.select(['B3', 'B2', 'B1'])\n",
    "    col_mean = trueColor.mosaic()\n",
    "\n",
    "    # images in the drive have been named corresponding to their index in the above output data structure\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image = col_mean,             \n",
    "        region = geometry,\n",
    "        description = '%d' % (index),\n",
    "        folder = \"world_images\",\n",
    "        scale = 30\n",
    "    )\n",
    "\n",
    "\n",
    "    task.start()\n",
    "    taskArray.append(task)\n",
    "    \n",
    "    if index == 2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'state': 'COMPLETED',\n 'description': '1',\n 'creation_timestamp_ms': 1590688264266,\n 'update_timestamp_ms': 1590688360987,\n 'start_timestamp_ms': 1590688337372,\n 'task_type': 'EXPORT_IMAGE',\n 'destination_uris': ['https://drive.google.com/#folders/1ElgN385_99oTuB05b4s44yqxhzz7HjpE'],\n 'id': 'MEK7ZWYRQ6J4MTYPLNVVJOID',\n 'name': 'projects/earthengine-legacy/operations/MEK7ZWYRQ6J4MTYPLNVVJOID'}"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "taskArray[1].status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('cs231n': conda)",
   "language": "python",
   "name": "python361064bitcs231ncondabcd0b8ccc2164f89a5b2ce10a19ab81e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}