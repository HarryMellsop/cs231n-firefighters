{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import geopandas\n",
    "from shapely.geometry import Polygon\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = sqlite3.connect('../us_wildfire_dataset/FPA_FOD_20170508.sqlite')\n",
    "df = pd.read_sql_query(\"SELECT DISCOVERY_DATE, CONT_DATE, LATITUDE, LONGITUDE, STATE, FIRE_NAME, FIRE_SIZE_CLASS, FIRE_SIZE,STAT_CAUSE_DESCR FROM fires\", cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def filter_raw_data(df, state='CA', min_class=None):\n",
    "\n",
    "    # drop states\n",
    "    df_filt = df[df.STATE == 'CA']\n",
    "    df_filt = df_filt.drop(['STATE'], axis=1)\n",
    "\n",
    "    # drop fire classes\n",
    "    if min_class is not None:\n",
    "        df_filt.FIRE_SIZE_CLASS = df_filt.FIRE_SIZE_CLASS.apply(ord)\n",
    "        df_filt = df_filt[df_filt.FIRE_SIZE_CLASS >= ord(min_class)]\n",
    "\n",
    "    # reformat dates\n",
    "    df_filt.DISCOVERY_DATE = pd.to_datetime(df['DISCOVERY_DATE'], unit='D', origin='julian')\n",
    "    df_filt.CONT_DATE = pd.to_datetime(df['CONT_DATE'], unit='D', origin='julian')\n",
    "\n",
    "    # convert coordinates\n",
    "    df_filt = geopandas.GeoDataFrame(df_filt, geometry=geopandas.points_from_xy(\n",
    "        df_filt.LONGITUDE, df_filt.LATITUDE))\n",
    "    df_filt = df_filt.drop(['LONGITUDE'], axis=1)\n",
    "    df_filt = df_filt.drop(['LATITUDE'], axis=1)\n",
    "    df_filt.insert(2, 'COORD', df_filt.pop('geometry'))\n",
    "\n",
    "    # remove missing values\n",
    "    df_filt = df_filt.dropna()\n",
    "\n",
    "    # reformat head\n",
    "    df_filt.columns = [\n",
    "        'start_date', 'end_date', 'geometry',\n",
    "        'name', 'size_class', 'size', 'cause'\n",
    "    ]\n",
    "\n",
    "    # sort by start dates\n",
    "    df_filt = df_filt.sort_values(by='start_date')\n",
    "    df_filt = df_filt.reset_index()\n",
    "\n",
    "    return df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def extract_geo_fires(df, area):\n",
    "\n",
    "    # return fires within polygon\n",
    "    res = df[df.within(area)]\n",
    "    return res\n",
    "\n",
    "\n",
    "def build_geo_grid(df, grid_area, square_size, verbose=False):\n",
    "    bounds = grid_area.bounds\n",
    "\n",
    "    # calculate number of grids in lat/long directions\n",
    "    long_steps = int((bounds[2] - bounds[0]) / square_size)\n",
    "    lat_steps = int((bounds[3] - bounds[1]) / square_size)\n",
    "\n",
    "    grid_df = []\n",
    "    prog, total = 0, long_steps * lat_steps\n",
    "    for i in range(long_steps):\n",
    "        for j in range(lat_steps):\n",
    "\n",
    "            # update progress\n",
    "            prog += 1\n",
    "            if verbose and prog % 10 == 0:\n",
    "                print('Progress: {}/{}'.format(prog, total), flush=True)\n",
    "            \n",
    "            # get south-east grid square corner\n",
    "            c_lon = bounds[0] + i * square_size\n",
    "            c_lat = bounds[1] + j * square_size\n",
    "\n",
    "            # create grid square\n",
    "            grid = Polygon([\n",
    "                (c_lon, c_lat), \n",
    "                (c_lon + square_size, c_lat), \n",
    "                (c_lon, c_lat + square_size), \n",
    "                (c_lon + square_size, c_lat + square_size)\n",
    "            ])\n",
    "            \n",
    "            fires = extract_geo_fires(df, grid)\n",
    "            grid_df.append([uuid.uuid4(), grid, fires.index])\n",
    "\n",
    "    # build grid df\n",
    "    grid_df = geopandas.GeoDataFrame(grid_df)\n",
    "    grid_df.columns = ['grid_id', 'grid_square', 'fire_indices']\n",
    "    return grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Progress: 10/256\nProgress: 20/256\nProgress: 30/256\nProgress: 40/256\nProgress: 50/256\nProgress: 60/256\nProgress: 70/256\nProgress: 80/256\nProgress: 90/256\nProgress: 100/256\nProgress: 110/256\nProgress: 120/256\nProgress: 130/256\nProgress: 140/256\nProgress: 150/256\nProgress: 160/256\nProgress: 170/256\nProgress: 180/256\nProgress: 190/256\nProgress: 200/256\nProgress: 210/256\nProgress: 220/256\nProgress: 230/256\nProgress: 240/256\nProgress: 250/256\n"
    }
   ],
   "source": [
    "# coordinate-square north of San Bernardino/Riverside \n",
    "p = Polygon([(-124, 38), (-124, 42), (-120, 38), (-120, 42)])\n",
    "\n",
    "# filter raw data from dataset and build sexy format\n",
    "df_filt = filter_raw_data(df, state='CA', min_class='C')\n",
    "\n",
    "# df_filt is ordered by start_date with the following columns:\n",
    "#   'start_date', 'end_date', 'geometry', 'name', 'size_class', 'size', 'cause'\n",
    "\n",
    "# build df with each grid square area (from grid area `p` with grid square size 0.1) and corresponding fires indices (which indexes complete list of fires in df_filt)\n",
    "grid_df = build_geo_grid(df_filt, p, 0.25, verbose=True)\n",
    "\n",
    "# grid_df has the following columns:\n",
    "#    'grid_id', 'grid_square', 'fire_indices'\n",
    "#    grid_id: a random uuid to identify the grid square for later\n",
    "#    grid_square: polygon object of the grid square\n",
    "#    fire_indices: list of indices of the fires from df_filt within the grid_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def label_grid_square(df, grid_df, start_date='1992-01', end_date='2015-12', verbose=False):\n",
    "    \n",
    "    # build date range (in months)\n",
    "    date_range = [str(d) for d in np.arange(\n",
    "        start_date, \n",
    "        end_date, \n",
    "        dtype='datetime64[M]'\n",
    "    )]    \n",
    "\n",
    "    # iterate over all grid squares \n",
    "    label_df = []\n",
    "    prog, total = 0, grid_df.shape[0]\n",
    "    for i in range(grid_df.shape[0]):\n",
    "        \n",
    "        # update progress\n",
    "        prog += 1\n",
    "        if verbose and prog % 10 == 0:\n",
    "            print('Progress: {}/{}'.format(prog, total), flush=True)\n",
    "                \n",
    "        # get grid square fires\n",
    "        id = grid_df.loc[i, 'grid_id']\n",
    "        grid_square = grid_df.loc[i, 'grid_square']\n",
    "        fire_indices = list(grid_df.loc[i, 'fire_indices'])\n",
    "        fires = df.loc[fire_indices, :]\n",
    "        \n",
    "        # collect all months in fire date range\n",
    "        months = []\n",
    "        for _, row in fires.iterrows(): \n",
    "            start = row.start_date.date()\n",
    "            end = (row.end_date + pd.DateOffset(months=1)).date()\n",
    "            months.extend([str(d) for d in np.arange(start, end, dtype='datetime64[M]')])\n",
    "        fire_months = list(set(months))\n",
    "        \n",
    "        # label fire months\n",
    "        month_labels = []\n",
    "        for month in date_range:\n",
    "            if month in fire_months: month_labels.append(1)\n",
    "            else: month_labels.append(0)\n",
    "        \n",
    "        # add labels\n",
    "        labels = [id, grid_square] + month_labels\n",
    "        label_df.append(labels)\n",
    "        \n",
    "    # build label df\n",
    "    label_df = pd.DataFrame(label_df)\n",
    "    label_df.columns = ['grid_id', 'grid_square'] + date_range\n",
    "    return label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# labels whether there was a fire in each grid square \n",
    "label_df = label_grid_square(df_filt, grid_df, start_date='2000-01', end_date='2015-12', verbose=False)\n",
    "\n",
    "# label_df has the following columns:\n",
    "#    'grid_id', 'grid_square', 'months ...'\n",
    "#    grid_id: a random uuid to identify the grid square for later\n",
    "#    grid_square: polygon object of the grid square\n",
    "#    indices: the rest of the columns are a label for each month (0 if there was no fire in the grid square during them onth and 1 otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "num_zeros = 0\n",
    "num_subsequent_1s = 0\n",
    "total_iters = 0\n",
    "for index, row in label_df.iterrows():\n",
    "    # because we are using Landsat 7, let's make sure we constrain dates to be from 2000 onwards (hence the + 96)\n",
    "\n",
    "    if np.sum(row[2:]) <= 3: continue\n",
    "    for rowIndex, col in enumerate(row[2 + 96:-1]):\n",
    "        # if not on fire\n",
    "        total_iters += 1\n",
    "        if col == 0:\n",
    "            num_zeros += 1\n",
    "            # include implicit conversion to tuple of bounds instead of polygon shape; will make working with earth engine easier\n",
    "            output.append((row[0], row[1].bounds, label_df.columns[rowIndex + 2 + 96], row[rowIndex + 1 + 2 + 96]))\n",
    "            if row[rowIndex + 1 + 2 + 96] == 1:\n",
    "                num_subsequent_1s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total iterations: 10622\nTotal data points: 10172\nTotal data points with 1-label: 263\nTotal data points with 0-label: 9909\nPercentage of 1s: 2.586%\n"
    }
   ],
   "source": [
    "print('Total iterations: {}'.format(total_iters))\n",
    "print('Total data points: {}'.format(num_zeros))\n",
    "print('Total data points with 1-label: {}'.format(num_subsequent_1s))\n",
    "print('Total data points with 0-label: {}'.format(num_zeros - num_subsequent_1s))\n",
    "print('Percentage of 1s: {}%'.format(round(num_subsequent_1s / num_zeros * 100, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# save the corresponding data structure to disk\n",
    "import pickle\n",
    "with open(\"../us_wildfire_dataset/labelled_temporal_polygons.pkl\", \"wb\") as f:\n",
    "    pickle.dump(output, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10172\n"
    }
   ],
   "source": [
    "# load output back from the pickle\n",
    "with open(\"../us_wildfire_dataset/labelled_temporal_polygons.pkl\", \"rb\") as f:\n",
    "    unpickler = pickle.Unpickler(f)\n",
    "    output = unpickler.load()\n",
    "    print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.000000 complete\n0.000983 complete\n0.001966 complete\n0.002949 complete\n0.003932 complete\n0.004915 complete\n0.005899 complete\n0.006882 complete\n0.007865 complete\n0.008848 complete\n0.009831 complete\n0.010814 complete\n0.011797 complete\n0.012780 complete\n0.013763 complete\n0.014746 complete\n0.015729 complete\n0.016713 complete\n0.017696 complete\n0.018679 complete\n0.019662 complete\n0.020645 complete\n0.021628 complete\n0.022611 complete\n0.023594 complete\n0.024577 complete\n0.025560 complete\n0.026543 complete\n0.027527 complete\n0.028510 complete\n0.029493 complete\n0.030476 complete\n0.031459 complete\n0.032442 complete\n0.033425 complete\n0.034408 complete\n0.035391 complete\n0.036374 complete\n0.037357 complete\n0.038341 complete\n0.039324 complete\n0.040307 complete\n0.041290 complete\n0.042273 complete\n0.043256 complete\n0.044239 complete\n0.045222 complete\n0.046205 complete\n0.047188 complete\n0.048171 complete\n0.049155 complete\n0.050138 complete\n0.051121 complete\n0.052104 complete\n0.053087 complete\n0.054070 complete\n0.055053 complete\n0.056036 complete\n0.057019 complete\n0.058002 complete\n0.058985 complete\n0.059969 complete\n0.060952 complete\n0.061935 complete\n0.062918 complete\n0.063901 complete\n0.064884 complete\n0.065867 complete\n0.066850 complete\n0.067833 complete\n0.068816 complete\n0.069799 complete\n0.070783 complete\n0.071766 complete\n0.072749 complete\n0.073732 complete\n0.074715 complete\n0.075698 complete\n0.076681 complete\n0.077664 complete\n0.078647 complete\n0.079630 complete\n0.080613 complete\n0.081597 complete\n0.082580 complete\n0.083563 complete\n0.084546 complete\n0.085529 complete\n0.086512 complete\n0.087495 complete\n0.088478 complete\n0.089461 complete\n0.090444 complete\n0.091427 complete\n0.092411 complete\n0.093394 complete\n0.094377 complete\n0.095360 complete\n0.096343 complete\n0.097326 complete\n0.098309 complete\n0.099292 complete\n0.100275 complete\n0.101258 complete\n0.102241 complete\n0.103225 complete\n0.104208 complete\n0.105191 complete\n0.106174 complete\n0.107157 complete\n0.108140 complete\n0.109123 complete\n0.110106 complete\n0.111089 complete\n0.112072 complete\n0.113055 complete\n0.114039 complete\n0.115022 complete\n0.116005 complete\n0.116988 complete\n0.117971 complete\n0.118954 complete\n0.119937 complete\n0.120920 complete\n0.121903 complete\n0.122886 complete\n0.123869 complete\n0.124853 complete\n0.125836 complete\n0.126819 complete\n0.127802 complete\n0.128785 complete\n0.129768 complete\n0.130751 complete\n0.131734 complete\n0.132717 complete\n0.133700 complete\n0.134683 complete\n0.135667 complete\n0.136650 complete\n0.137633 complete\n0.138616 complete\n0.139599 complete\n0.140582 complete\n0.141565 complete\n0.142548 complete\n0.143531 complete\n0.144514 complete\n0.145497 complete\n0.146481 complete\n0.147464 complete\n0.148447 complete\n0.149430 complete\n0.150413 complete\n0.151396 complete\n0.152379 complete\n0.153362 complete\n0.154345 complete\n0.155328 complete\n0.156311 complete\n0.157295 complete\n0.158278 complete\n0.159261 complete\n0.160244 complete\n0.161227 complete\n0.162210 complete\n0.163193 complete\n0.164176 complete\n0.165159 complete\n0.166142 complete\n0.167125 complete\n0.168109 complete\n0.169092 complete\n0.170075 complete\n0.171058 complete\n0.172041 complete\n0.173024 complete\n0.174007 complete\n0.174990 complete\n0.175973 complete\n0.176956 complete\n0.177939 complete\n0.178923 complete\n0.179906 complete\n0.180889 complete\n0.181872 complete\n0.182855 complete\n0.183838 complete\n0.184821 complete\n0.185804 complete\n0.186787 complete\n0.187770 complete\n0.188753 complete\n0.189737 complete\n0.190720 complete\n0.191703 complete\n0.192686 complete\n0.193669 complete\n0.194652 complete\n0.195635 complete\n0.196618 complete\n0.197601 complete\n0.198584 complete\n0.199567 complete\n0.200551 complete\n0.201534 complete\n0.202517 complete\n0.203500 complete\n0.204483 complete\n0.205466 complete\n0.206449 complete\n0.207432 complete\n0.208415 complete\n0.209398 complete\n0.210381 complete\n0.211365 complete\n0.212348 complete\n0.213331 complete\n0.214314 complete\n0.215297 complete\n0.216280 complete\n0.217263 complete\n0.218246 complete\n0.219229 complete\n0.220212 complete\n0.221195 complete\n0.222179 complete\n0.223162 complete\n0.224145 complete\n0.225128 complete\n0.226111 complete\n0.227094 complete\n0.228077 complete\n0.229060 complete\n0.230043 complete\n0.231026 complete\n0.232009 complete\n0.232993 complete\n0.233976 complete\n0.234959 complete\n0.235942 complete\n0.236925 complete\n0.237908 complete\n0.238891 complete\n0.239874 complete\n0.240857 complete\n0.241840 complete\n0.242823 complete\n0.243807 complete\n0.244790 complete\n0.245773 complete\n0.246756 complete\n0.247739 complete\n0.248722 complete\n0.249705 complete\n0.250688 complete\n0.251671 complete\n0.252654 complete\n0.253637 complete\n0.254621 complete\n0.255604 complete\n0.256587 complete\n0.257570 complete\n0.258553 complete\n0.259536 complete\n0.260519 complete\n0.261502 complete\n0.262485 complete\n0.263468 complete\n0.264451 complete\n0.265435 complete\n0.266418 complete\n0.267401 complete\n0.268384 complete\n0.269367 complete\n0.270350 complete\n0.271333 complete\n0.272316 complete\n0.273299 complete\n0.274282 complete\n0.275265 complete\n0.276249 complete\n0.277232 complete\n0.278215 complete\n0.279198 complete\n0.280181 complete\n0.281164 complete\n0.282147 complete\n0.283130 complete\n0.284113 complete\n0.285096 complete\n0.286079 complete\n0.287063 complete\n0.288046 complete\n0.289029 complete\n0.290012 complete\n0.290995 complete\n0.291978 complete\n0.292961 complete\n0.293944 complete\n0.294927 complete\n0.295910 complete\n0.296893 complete\n0.297877 complete\n0.298860 complete\n"
    },
    {
     "output_type": "error",
     "ename": "EEException",
     "evalue": "Too many tasks already in the queue (3000). Please wait for some of them to complete.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/opt/miniconda3/envs/cs231n/lib/python3.6/site-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs231n/lib/python3.6/site-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs231n/lib/python3.6/site-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/image:export?alt=json returned \"Too many tasks already in the queue (3000). Please wait for some of them to complete.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2b16ac1a4e4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mtaskArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs231n/lib/python3.6/site-packages/ee/batch.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPORT_IMAGE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexportImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPORT_MAP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexportMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs231n/lib/python3.6/site-packages/ee/data.py\u001b[0m in \u001b[0;36mexportImage\u001b[0;34m(request_id, params)\u001b[0m\n\u001b[1;32m   1336\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_use_cloud_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m     return _prepare_and_run_export(\n\u001b[0;32m-> 1338\u001b[0;31m         request_id, params, _cloud_api_resource.projects().image().export)\n\u001b[0m\u001b[1;32m   1339\u001b[0m   \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EXPORT_IMAGE'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mstartProcessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs231n/lib/python3.6/site-packages/ee/data.py\u001b[0m in \u001b[0;36m_prepare_and_run_export\u001b[0;34m(request_id, params, export_endpoint)\u001b[0m\n\u001b[1;32m   1461\u001b[0m   return _execute_cloud_call(\n\u001b[1;32m   1462\u001b[0m       \u001b[0mexport_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_projects_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1463\u001b[0;31m       num_retries=num_retries)\n\u001b[0m\u001b[1;32m   1464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs231n/lib/python3.6/site-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0m_translate_cloud_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEEException\u001b[0m: Too many tasks already in the queue (3000). Please wait for some of them to complete."
     ]
    }
   ],
   "source": [
    "from calendar import monthrange\n",
    "\n",
    "totalIters = len(output)\n",
    "taskArray = []\n",
    "\n",
    "# change this number 10 to eventually download all of the required images.\n",
    "for index, item in enumerate(output):\n",
    "    uuid, coords, date, label = item\n",
    "    year, month = date.split(\"-\")\n",
    "    year, month = int(year), int(month)\n",
    "\n",
    "    if index % 10 == 0: print(\"%f complete\" % (float(index) / float(totalIters)))\n",
    "\n",
    "    geometry = ee.Geometry.Rectangle(list(coords))\n",
    "\n",
    "    # because we are using LANDSAT7, we need to constrain our dates from 2000 onwards; so far, this has been done above (in cell 96)\n",
    "    collection = ee.ImageCollection(\"LANDSAT/LE07/C01/T1\").filterDate(ee.Date.fromYMD(year, month, 1), ee.Date.fromYMD(year, month, monthrange(year, month)[1])).filterBounds(geometry)\n",
    "    trueColor = collection.select(['B3', 'B2', 'B1'])\n",
    "    col_mean = trueColor.mosaic()\n",
    "\n",
    "    # images in the drive have been named corresponding to their index in the above output data structure\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image = col_mean,             \n",
    "        region = geometry,\n",
    "        description = '%d' % (index),\n",
    "        folder = \"world_images\",\n",
    "        scale = 30\n",
    "    )\n",
    "\n",
    "    task.start()\n",
    "    taskArray.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'state': 'COMPLETED',\n 'description': '886',\n 'creation_timestamp_ms': 1589988656129,\n 'update_timestamp_ms': 1589988692038,\n 'start_timestamp_ms': 1589988661782,\n 'task_type': 'EXPORT_IMAGE',\n 'destination_uris': ['https://drive.google.com/#folders/1MYfA2k6Hh9xjQQE9nSvcX7Lz-RMACeBc'],\n 'id': 'VJU2UMGUZ2VC3XQ7WWS5MVHB',\n 'name': 'projects/earthengine-legacy/operations/VJU2UMGUZ2VC3XQ7WWS5MVHB'}"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "task.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}